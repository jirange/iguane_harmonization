import numpy as np
import os
import re
import nibabel as nib
import tensorflow as tf
from skimage.metrics import structural_similarity
from tqdm import tqdm

# ===================== æ ¸å¿ƒé…ç½®ï¼ˆéœ€æ ¹æ®å®é™…è·¯å¾„ä¿®æ”¹ï¼‰ =====================
# MODEL_WEIGHTS_PATH = "/home/lengjingcheng/codes/iguane_harmonization/harmonization/iguane_weights.h5"  # ç°æœ‰æ¨¡å‹æƒé‡è·¯å¾„
MODEL_WEIGHTS_PATH = "/home/lengjingcheng/codes/iguane_harmonization/harmonization/my_train_sald-ixi-abide-100epoch/best_genUniv.h5"  # ç°æœ‰æ¨¡å‹æƒé‡è·¯å¾„
# VAL_DATA_PATH = "/home/lengjingcheng/codes/iguane_harmonization/data/ON-Harmony/preprocessed/"  # éªŒè¯é›†è·¯å¾„
VAL_DATA_PATH = "/nas/ljc/SRPBS_TS/preprocessed/"  # éªŒè¯é›†è·¯å¾„
TARGET_SHAPE = (160, 192, 160)  # æ¨¡å‹è¾“å…¥æ ‡å‡†å°ºå¯¸

# 0.8950 my_train_sald-ixi-abide-100epoch/latest_genUniv.h5
# 0.8998 my_train_sald-ixi-abide-100epoch/best_genUniv.h5
# 0.9296 iguane_weights.h5   è®ºæ–‡æƒé‡   0.9252 0.0044  

# 0.8759 my_train_sald-ixi-check/latest_genUniv.h5 ï¼ˆ60 epochï¼‰

# 0.9483 my_train/best_genUniv.h5   ?????ä¸ºå•¥è¿™ä¹ˆé«˜ï¼Œä¸ä¼šæ˜¯å› ä¸ºå¼„æˆå…¨é»‘çš„äº†æ‰€ä»¥é«˜å§ï¼Ÿ
# 0.8754 my_train2/best_genUniv.h5
# 0.9331 20ä¸ªepoch çš„ my_train_sald-ixi2-abide2/latest_genUniv.h5  ä¸ºä»€ä¹ˆè¿™ä¹ˆé«˜ï¼Œå’Œå…¨é»‘åŒç†ï¼Ÿçœ‹ä¸€ä¸‹çœŸå®å›¾ç‰‡å§


# 0.9335 my_train_sald-ixi2-abide2  å¥½é«˜ï¼Œæ˜¯å› ä¸ºå˜æˆå››ä¸ªlistäº†å—  0.9252   0.0083

# iguane_weights.h5: æœ€ç»ˆéªŒè¯ç»“æœï¼šè·¨ç«™ç‚¹SSIMå‡å€¼ = (0.9107870531411447, 0.9108073729488664)
# my_train_sald-ixi2-abide2      è·¨ç«™ç‚¹SSIMå‡å€¼ = (0.9107870531411447, 0.835291971243021)
# my_train_sald-ixi-abide-100epoch/best_genUniv.h5 0.8749108255028624
# é¢„å¤„ç†å›¾åƒå¹³å‡SSIM=0.9108ï¼ˆæœ‰æ•ˆå›¾åƒå¯¹ï¼š1035ï¼‰
# åè°ƒåå›¾åƒå¹³å‡SSIM=0.8353ï¼ˆæœ‰æ•ˆå›¾åƒå¯¹ï¼š1035ï¼‰

# å¦‚ä½•éªŒè¯æ˜¯ä¸æ˜¯æœ‰SALDé£æ ¼å‘¢ï¼Ÿå¦‚ä½•éªŒè¯æ˜¯å¦æœ‰ç”Ÿç‰©ä¿çœŸæ€§å‘¢ï¼Ÿï¼Ÿ
# ===================== è¾…åŠ©å‡½æ•°ï¼šåŠ è½½éªŒè¯æ•°æ® =====================
def load_core_validation_data(val_data_path):
    """åŠ è½½é¢„å¤„ç†åçš„éªŒè¯é›†å›¾åƒåŠå—è¯•è€…ID"""
    val_imgs = []
    val_sub_ids = []
    for file_name in os.listdir(val_data_path):
        if file_name.endswith(".nii.gz") and "sub-" in file_name:
            # åŠ è½½å›¾åƒå¹¶å¼ºåˆ¶æ ‡å‡†åŒ–å°ºå¯¸
            img = nib.load(os.path.join(val_data_path, file_name)).get_fdata()
            # print("å·²ç»åŠ è½½å›¾åƒæ•°æ® ",os.path.join(val_data_path, file_name))
            # è£å‰ª/å¡«å……åˆ°æ ‡å‡†å°ºå¯¸ï¼ˆé¿å…å°ºå¯¸ä¸åŒ¹é…ï¼‰
            h, w, d = img.shape
            start_h = max(0, (h - TARGET_SHAPE[0]) // 2)
            start_w = max(0, (w - TARGET_SHAPE[1]) // 2)
            start_d = max(0, (d - TARGET_SHAPE[2]) // 2)
            img = img[start_h:start_h+TARGET_SHAPE[0],
                      start_w:start_w+TARGET_SHAPE[1],
                      start_d:start_d+TARGET_SHAPE[2]]
            # å¡«å……ä¸è¶³éƒ¨åˆ†ä¸º0
            pad_h = TARGET_SHAPE[0] - img.shape[0]
            pad_w = TARGET_SHAPE[1] - img.shape[1]
            pad_d = TARGET_SHAPE[2] - img.shape[2]
            img = np.pad(img, ((0, pad_h), (0, pad_w), (0, pad_d)), mode='constant')
            
            val_imgs.append(img)
            # è§£æå—è¯•è€…ID
            sub_id = re.findall(r"sub-\d+", file_name)[0]
            val_sub_ids.append(sub_id)
    return np.array(val_imgs), val_sub_ids

# ===================== æ ¸å¿ƒå‡½æ•°ï¼šè®¡ç®—SSIM =====================
def calculate_subject_ssim(images_list, subject_ids):
    """è®¡ç®—åŒä¸€å—è¯•è€…è·¨ç«™ç‚¹çš„SSIMå‡å€¼"""
    ssim_scores = []
    unique_subs = np.unique(subject_ids)
    
    for sub_id in tqdm(unique_subs, desc="è®¡ç®—SSIM"):
        # è·å–è¯¥å—è¯•è€…çš„æ‰€æœ‰å›¾åƒ
        sub_images = [img for img, sid in zip(images_list, subject_ids) if sid == sub_id]
        if len(sub_images) < 2:
            continue
        
        # éå†æ‰€æœ‰å›¾åƒå¯¹
        for i in range(len(sub_images)):
            for j in range(i+1, len(sub_images)):
                # ä½¿ç”¨99ç™¾åˆ†ä½æ•°ä½œä¸ºåŠ¨æ€èŒƒå›´
                max_val = np.percentile(np.concatenate([
                    sub_images[i].ravel(), 
                    sub_images[j].ravel()
                ]), 99)
                
                ssim_val = structural_similarity(
                    sub_images[i], sub_images[j],
                    data_range=max_val, win_size=7, multichannel=False
                )
                ssim_scores.append(ssim_val)
    
    return np.mean(ssim_scores) if ssim_scores else 0.0, len(ssim_scores)

# ===================== æ ¸å¿ƒéªŒè¯å‡½æ•° =====================
def eval_model(gen_univ, val_data_path):
    """åŠ è½½éªŒè¯é›†â†’æ¨¡å‹æ¨ç†â†’è®¡ç®—SSIMå‡å€¼"""
    # 1. åŠ è½½éªŒè¯æ•°æ®
    val_imgs, val_sub_ids = load_core_validation_data(val_data_path)
    print(val_sub_ids)
    print(f"åŠ è½½äº†{len(val_imgs)}å¼ å›¾åƒ")
    if len(val_imgs) == 0:
        print("âš ï¸ æœªåŠ è½½åˆ°ä»»ä½•éªŒè¯å›¾åƒ")
        return 0.0
    
    preprocessed_ssim=0
    # # 2. è®¡ç®—åŸå§‹é¢„å¤„ç†å›¾åƒçš„SSIM
    # print("\n" + "="*50)
    # print("ğŸ“Š æ­£åœ¨è®¡ç®—é¢„å¤„ç†å›¾åƒçš„SSIM...")
    # print("="*50)
    # preprocessed_ssim, pre_pairs = calculate_subject_ssim(val_imgs, val_sub_ids)
    # print(f"âœ… é¢„å¤„ç†å›¾åƒå¹³å‡SSIM={preprocessed_ssim:.4f}ï¼ˆæœ‰æ•ˆå›¾åƒå¯¹ï¼š{pre_pairs}ï¼‰\n")
    

    # 2. ç”Ÿæˆåè°ƒåå›¾åƒï¼ˆå†»ç»“ç”Ÿæˆå™¨ï¼‰
    gen_univ.trainable = False
    harmonized_imgs = []
    for img in tqdm(val_imgs):
        # print(f'[debug] gold  {img.min():.1f} ~ {img.max():.1f}')

        # é¢„å¤„ç†ï¼ˆä¸è®­ç»ƒé€»è¾‘ä¸€è‡´ï¼‰
        mask = img > 0
        # img_norm = img / 500 - 1  # å¼ºåº¦å½’ä¸€åŒ–
        img_norm = img - 1  # å¼ºåº¦å½’ä¸€åŒ–
        img_norm[~mask] = 0
        
        # æ¨¡å‹æ¨ç†
        img_input = np.expand_dims(img_norm, axis=(0, 4))  # [1,160,192,160,1]
        img_tensor = tf.convert_to_tensor(img_input, dtype='float32')
        harmonized = gen_univ(img_tensor, training=False).numpy().squeeze()
        # print(f'[debug] harm {harmonized.min():.1f} ~ {harmonized.max():.1f}')

        # åå¤„ç†
        # harmonized = (harmonized + 1) * 500
        harmonized = harmonized + 1
        harmonized[~mask] = 0
        harmonized = np.maximum(harmonized, 0)
        # print(f'[debug] harm {harmonized.min():.1f} ~ {harmonized.max():.1f}')

        harmonized_imgs.append(harmonized)
    gen_univ.trainable = True

    # # 3. è®¡ç®—åŒä¸€å—è¯•è€…è·¨ç«™ç‚¹SSIMå‡å€¼
    # ssim_scores = []
    # unique_subs = np.unique(val_sub_ids)
    # print(len(unique_subs),unique_subs)
    # for sub_id in tqdm(unique_subs):
    #     sub_harmonized = [h for h, sid in zip(harmonized_imgs, val_sub_ids) if sid == sub_id]
    #     if len(sub_harmonized) < 2:
    #         continue
    #     # éå†è¯¥å—è¯•è€…æ‰€æœ‰å›¾åƒå¯¹
    #     for i in range(len(sub_harmonized)):
    #         for j in range(i+1, len(sub_harmonized)):
    #             max_val = np.percentile(np.concatenate([sub_harmonized[i].ravel(), sub_harmonized[j].ravel()]), 99)
    #             ssim_val = structural_similarity(
    #                 sub_harmonized[i], sub_harmonized[j],
    #                 data_range=max_val, win_size=7, multichannel=False
    #             )
    #             ssim_scores.append(ssim_val)
    
    # # 4. è¿”å›SSIMå‡å€¼
    # avg_ssim = np.mean(ssim_scores) if ssim_scores else 0.0
    # print(f"\nâœ… éªŒè¯å®Œæˆï¼šæœ‰æ•ˆå›¾åƒå¯¹{len(ssim_scores)}ç»„ | å¹³å‡SSIM={avg_ssim:.4f}")
    # return avg_ssim


    # 4. è®¡ç®—åè°ƒåå›¾åƒçš„SSIM
    harmonized_ssim, harm_pairs = calculate_subject_ssim(harmonized_imgs, val_sub_ids)
    print(f"âœ… åè°ƒåå›¾åƒå¹³å‡SSIM={harmonized_ssim:.4f}ï¼ˆæœ‰æ•ˆå›¾åƒå¯¹ï¼š{harm_pairs}ï¼‰\n")
    
    return preprocessed_ssim, harmonized_ssim

# ===================== ä¸»æ‰§è¡Œé€»è¾‘ =====================
if __name__ == "__main__":
    # 1. åˆå§‹åŒ–æ¨¡å‹å¹¶åŠ è½½æƒé‡
    print(f"ğŸ” åŠ è½½æ¨¡å‹æƒé‡ï¼š{MODEL_WEIGHTS_PATH}")
    import sys
    sys.path.append('..')
    from model_architectures import Generator
    gen_univ = Generator()  # åˆå§‹åŒ–è®ºæ–‡å®šä¹‰çš„Generatoræ¶æ„
    gen_univ.load_weights(MODEL_WEIGHTS_PATH)
    print("âœ… æ¨¡å‹æƒé‡åŠ è½½å®Œæˆ")
    
    # 2. æ‰§è¡ŒéªŒè¯
    print(f"\nğŸ” å¼€å§‹éªŒè¯ï¼ŒéªŒè¯é›†è·¯å¾„ï¼š{VAL_DATA_PATH}")
    avg_ssim = eval_model(gen_univ, VAL_DATA_PATH)
    
    # 3. è¾“å‡ºç»“æœ
    print(f"\nğŸ“Š {MODEL_WEIGHTS_PATH} æœ€ç»ˆéªŒè¯ç»“æœï¼šè·¨ç«™ç‚¹SSIMå‡å€¼ = {avg_ssim}")
